{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d215af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src folder to path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from boutdata import collect\n",
    "import math \n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softplus\n",
    "from torch.distributions import Distribution, Bernoulli\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "from functools import reduce\n",
    "from typing import *\n",
    "import matplotlib\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from eval_plots import plot_training_curves, make_plasma_vae_plots\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610219e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LOCATION = Path(\n",
    "\tr\"../data_numpy/density128.npy\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def plot_timestep(density,idx):\n",
    "\tplt.figure()\n",
    "\tplt.imshow(density[idx,:,:].T, origin='lower', cmap='viridis')\n",
    "\tplt.colorbar(label=\"n (arb. units)\")\n",
    "\tplt.xlabel(\"x index\")\n",
    "\tplt.ylabel(\"z index\")\n",
    "\tplt.title(\"Density at timestep 50\")\n",
    "\tplt.grid(False)\n",
    "\tplt.show()\n",
    "\n",
    "data = np.load(DATA_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = np.max(data)\n",
    "density_data = data/max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce3398",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timestep(density_data, idx=10)\n",
    "\n",
    "# It seems to be fitting to have the edge of the man plasma at x = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007851d",
   "metadata": {},
   "source": [
    "As one can see above, convergence first happens after some timesteps. An appropriate timestep for convergence would be $t = 23$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43525b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "data_tensor = torch.tensor(density_data, dtype=torch.float32)\n",
    "data_tensor = data_tensor.unsqueeze(1)  # add channel dim: [N, 1, H, W]\n",
    "\n",
    "print(data_tensor.shape) # Ensure data shape matches expectation!\n",
    "\n",
    "# train and validation split\n",
    "total_count = len(data_tensor)\n",
    "train_size = int(0.8 * total_count)\n",
    "test_size = total_count - train_size\n",
    "\n",
    "# Split data_tensor (not data!) so batches have channel dimension\n",
    "train_dataset, test_dataset = random_split(data_tensor, [train_size, test_size])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab58fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a representative training sample\n",
    "batch = next(iter(train_loader))\n",
    "sample = batch[0]  # pick first image from batch (shape: H, W)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(sample.T, origin='lower', cmap=\"viridis\")\n",
    "plt.title(\"Training sample\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494b580",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    \"\"\"\n",
    "    A distribution `N(y | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, 1)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: Tensor, log_sigma:Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        \"\"\"`\\eps ~ N(0, I)`\"\"\"\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (without gradients)\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
    "        epsilon = self.sample_epsilon()\n",
    "        return self.mu + self.sigma * epsilon\n",
    "            \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        \"\"\"return the log probability: log `p(z)`\"\"\"\n",
    "        return -0.5 * (math.log(2 * math.pi) + 2 * torch.log(self.sigma) + ((z - self.mu) ** 2) / (self.sigma ** 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8777b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a logistic distribution now\n",
    "\n",
    "class Logistic(Distribution):\n",
    "    arg_constraints = {}\n",
    "    support = torch.distributions.constraints.real\n",
    "    has_rsample = True\n",
    "\n",
    "    def __init__(self, loc, scale, validate_args=False):\n",
    "        self.loc = loc\n",
    "        self.scale = scale\n",
    "        super().__init__(validate_args=validate_args)\n",
    "\n",
    "    def rsample(self, sample_shape=torch.Size()):\n",
    "        eps = torch.rand(sample_shape + self.loc.shape, device=self.loc.device)\n",
    "        return self.loc + self.scale * torch.log(eps / (1 - eps))\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        z = (x - self.loc) / self.scale\n",
    "        return -z - torch.log(self.scale) - 2 * torch.log1p(torch.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64755b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalVariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_shape:torch.Size, latent_features: int, in_channels: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        # Convolutional encoder keeps the code compact while extracting spatial features.\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            # Block 1: 128 -> 64\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Block 2: 64 -> 32\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Block 3: 32 -> 16\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Block 4: 16 -> 8\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            # Flattened size: 256 channels * 8 * 8 = 16384\n",
    "            nn.Linear(256 * 8 * 8, latent_features * 2) \n",
    "        )\n",
    "\n",
    "        \n",
    "        self.conv_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_features, 256 * 8 * 8), # Upscale linear layer\n",
    "            nn.Unflatten(dim=1, unflattened_size=(256, 8, 8)), # Reshape\n",
    "            \n",
    "            # Block 1: 8 -> 16\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Block 2: 16 -> 32\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Block 3: 32 -> 64\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Block 4: 64 -> 128\n",
    "            nn.ConvTranspose2d(32, in_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Prior parameters stay identical to the dense version.\n",
    "        self.register_buffer(\"prior_params\", torch.zeros(1, 2 * latent_features))\n",
    "\n",
    "        # Define the learnable log-scale parameter\n",
    "        self.log_scale = nn.Parameter(torch.tensor([0.0]))\n",
    "\n",
    "        \n",
    "    def posterior(self, x:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `q(x|x) = N(z | \\mu(x), \\sigma(x))`\"\"\"\n",
    "\n",
    "        # compute the parameters of the posterior\n",
    "        h_x = self.conv_encoder(x)\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1)\n",
    "\n",
    "        log_sigma = torch.clamp(log_sigma,min=-10, max=10)\n",
    "        \n",
    "        # return a distribution `q(x|x) = N(z | \\mu(x), \\sigma(x))`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        \n",
    "    def prior(self, batch_size:int=1)-> Distribution:\n",
    "        \"\"\"return the distribution `p(z)`\"\"\"\n",
    "        prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = prior_params.chunk(2, dim=-1)\n",
    "        \n",
    "        # return the distribution `p(z)`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        \n",
    "    # def observation_model(self, z:Tensor) -> Distribution:\n",
    "    #     \"\"\"return the distribution `p(x|z)`\"\"\"\n",
    "    #     px_logits = self.conv_decoder(z)\n",
    "    #     #px_logits = px_logits.view(-1, *self.input_shape) # reshape the output\n",
    "    #     return Bernoulli(logits=px_logits, validate_args=False)\n",
    "    \n",
    "    def observation_model(self, z:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `p(x|z)`\"\"\"\n",
    "        mu = self.conv_decoder(z)\n",
    "        #scale = 0.1 # Fixed standard deviation #TODO. look at this\n",
    "        scale = torch.exp(self.log_scale)\n",
    "        return torch.distributions.Normal(mu, scale)\n",
    "        \n",
    "    def forward(self, x) -> Dict[str, Any]:\n",
    "        \"\"\"compute the posterior q(z|x) (encoder), sample z~q(z|x) and return the distribution p(x|z) (decoder)\"\"\"\n",
    "        \n",
    "        # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        qz = self.posterior(x)\n",
    "        \n",
    "        # define the prior p(z)\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "        \n",
    "        # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        z = qz.rsample()\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}\n",
    "        \n",
    "    def sample_from_prior(self, batch_size: int = 16) -> Dict[str, Any]:\n",
    "        pz = self.prior(batch_size=batch_size)\n",
    "        z = pz.rsample()\n",
    "        px = self.observation_model(z)\n",
    "        return {\"px\": px, \"pz\": pz, \"z\": z}\n",
    "\n",
    "\n",
    "latent_features = 2\n",
    "# Example usage once you have tensors shaped as (batch, 1, H, W):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de41c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(x:Tensor) -> Tensor:\n",
    "    \"\"\"for each datapoint: sum over all dimensions\"\"\"\n",
    "    return x.view(x.size(0), -1).sum(dim=1)\n",
    "\n",
    "class VariationalInference(nn.Module):\n",
    "    def __init__(self, beta:float=1.):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward(self, model:nn.Module, x:Tensor) -> Tuple[Tensor, Dict]:\n",
    "        \n",
    "        # forward pass through the model\n",
    "        outputs = model(x)\n",
    "        \n",
    "        # unpack outputs\n",
    "        px, pz, qz, z = [outputs[k] for k in [\"px\", \"pz\", \"qz\", \"z\"]]\n",
    "        \n",
    "        # evaluate log probabilities\n",
    "        log_px = reduce(px.log_prob(x))\n",
    "        log_pz = reduce(pz.log_prob(z))\n",
    "        log_qz = reduce(qz.log_prob(z))\n",
    "        \n",
    "        # compute the ELBO with and without the beta parameter: \n",
    "        # `L^\\beta = E_q [ log p(x|z) ] - \\beta * D_KL(q(z|x) | p(z))`\n",
    "        # where `D_KL(q(z|x) | p(z)) = log q(z|x) - log p(z)`\n",
    "        kl = log_qz - log_pz\n",
    "        elbo = log_px - kl\n",
    "        beta_elbo = log_px - self.beta * kl\n",
    "        \n",
    "        # loss\n",
    "        loss = -beta_elbo.mean()\n",
    "        \n",
    "        # prepare the output\n",
    "        with torch.no_grad():\n",
    "            diagnostics = {'elbo': elbo, 'log_px':log_px, 'kl': kl}\n",
    "            \n",
    "        return loss, diagnostics, outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc63cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(density_data[22,:,:].shape)\n",
    "test = torch.tensor(data[22,:,:], dtype=torch.float32).clone()\n",
    "print(test.shape)\n",
    "test = test.unsqueeze(0).unsqueeze(0)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if valid dimensions in Convolutional VAE\n",
    "dummy_tensor = test\n",
    "#dummy_tensor = torch.tensor(density_data[0,:,:,:].reshape(1,1028,1024), dtype=torch.float32)\n",
    "C_VAE = ConvolutionalVariationalAutoencoder(dummy_tensor.shape, latent_features)\n",
    "# Going manually through the the forward() method\n",
    "\n",
    "# define the posterior q(z|x) / encode x into q(z|x)\n",
    "qz = C_VAE.posterior(dummy_tensor)\n",
    "\n",
    "# define the prior p(z)\n",
    "pz = C_VAE.prior(batch_size=dummy_tensor.size(0))\n",
    "\n",
    "# sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "z = qz.rsample()\n",
    "\n",
    "# define the observation model p(x|z) = B(x | g(z))\n",
    "px = C_VAE.observation_model(z)\n",
    "\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = test\n",
    "\n",
    "vi = VariationalInference(beta=1.0)\n",
    "loss, diagnostics, outputs = vi(C_VAE, images)\n",
    "print(f\"{'loss':6} | mean = {loss:10.3f}, shape: {list(loss.shape)}\")\n",
    "for key, tensor in diagnostics.items():\n",
    "    print(f\"{key:6} | mean = {tensor.mean():10.3f}, shape: {list(tensor.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfffb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# define the models, evaluator and optimizer\n",
    "\n",
    "# VAE\n",
    "latent_features = 16\n",
    "cvae = ConvolutionalVariationalAutoencoder(images[0].shape, latent_features)\n",
    "\n",
    "# Evaluator: Variational Inference\n",
    "beta = 0.75\n",
    "vi = VariationalInference(beta=beta)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-3)\n",
    "\n",
    "# define dictionary to store the training curves\n",
    "training_data = defaultdict(list)\n",
    "validation_data = defaultdict(list)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f8cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "\n",
    "# Try plotting the dummy data\n",
    "\n",
    "\"\"\"Plot the density at the final time step.\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "contour = ax.contourf(dummy_tensor[0, 0, :, :].T)\n",
    "fig.colorbar(contour, ax=ax, label=\"n (arb. units)\")\n",
    "ax.set_title(\"Density at final timestep\")\n",
    "ax.set_xlabel(\"x index\")\n",
    "ax.set_ylabel(\"z index\")\n",
    "ax.vlines(128, 0, 128)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,14))\n",
    "# --------------------\n",
    "# Input (left)\n",
    "# --------------------\n",
    "axes[0].set_title(\"Input Samples\")\n",
    "x_input = dummy_tensor  # [B, C, H, W]\n",
    "\n",
    "# Make sure it's a NumPy array for slicing\n",
    "img = x_input[0, 0].cpu().numpy().T[::-1, :]  # transpose + flip horizontally\n",
    "axes[0].imshow(img, cmap='rocket')\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# --------------------\n",
    "# Reconstruction (right)\n",
    "# --------------------\n",
    "\n",
    "axes[1].set_title(\"Reconstruction Samples\")\n",
    "# x_hat_sample = px.sample().squeeze(2)  # [B, C, H, W]\n",
    "# img_hat = px.probs[0,0].cpu().detach().numpy().T[::-1, :]\n",
    "img_hat = px.mean[0, 0].cpu().detach().numpy().T[::-1, :]\n",
    "# img_hat = x_hat_sample[0, 0, :, :].cpu().numpy().T[::-1, :]\n",
    "axes[1].imshow(img_hat, cmap='rocket')\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# make_plasma_vae_plots(C_VAE, px, outputs, training_data, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde37d0a",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd92eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# define the models, evaluator and optimizer\n",
    "\n",
    "# CVAE\n",
    "latent_features = 26\n",
    "cvae = ConvolutionalVariationalAutoencoder(images[0].shape, latent_features)\n",
    "\n",
    "# Evaluator: Variational Inference\n",
    "beta = 0.75 # Might change\n",
    "vi = VariationalInference(beta=beta)\n",
    "\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-3)\n",
    "\n",
    "# define dictionary to store the training curves\n",
    "training_data = defaultdict(list)\n",
    "validation_data = defaultdict(list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab14bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "# move the model to the device\n",
    "cvae = cvae.to(device)\n",
    "\n",
    "# training..\n",
    "epoch = 0\n",
    "while epoch < num_epochs:\n",
    "    epoch+= 1\n",
    "\n",
    "    training_epoch_data = defaultdict(list)\n",
    "    cvae.train()\n",
    "    \n",
    "    # Go through each batch in the training dataset using the loader\n",
    "    # Note that y is not necessarily known as it is here\n",
    "    for x in train_loader:\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # perform a forward pass through the model and compute the ELBO\n",
    "        loss, diagnostics, outputs = vi(cvae, x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clip to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(cvae.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        # gather data for the current bach\n",
    "        for k, v in diagnostics.items():\n",
    "            training_epoch_data[k] += [v.mean().item()]\n",
    "      \n",
    "\n",
    "    # gather data for the full epoch\n",
    "    for k, v in training_epoch_data.items():\n",
    "        training_data[k] += [np.mean(training_epoch_data[k])]\n",
    "\n",
    "    # Evaluate on the full test set, do not propagate gradients\n",
    "    with torch.no_grad():\n",
    "        cvae.eval()\n",
    "        \n",
    "        validation_epoch_data = defaultdict(list)\n",
    "        \n",
    "        # Iterate through the entire test loader\n",
    "        for x in test_loader:\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # perform a forward pass through the model and compute the ELBO\n",
    "            loss, diagnostics, outputs = vi(cvae, x)\n",
    "            \n",
    "            # gather data for the validation step\n",
    "            for k, v in diagnostics.items():\n",
    "                validation_epoch_data[k] += [v.mean().item()]\n",
    "        \n",
    "        # Average the metrics over the validation set and store\n",
    "        for k, v in validation_epoch_data.items():\n",
    "            validation_data[k] += [np.mean(v)]\n",
    "    \n",
    "    #print(f\"{epoch} iterations completed\")\n",
    "    # Reproduce the figure from the begining of the notebook, plot the training curves and show latent samples\n",
    "    if epoch % 10 == 0:\n",
    "        #make_plasma_vae_plots(cvae, x, outputs, training_data, validation_data)\n",
    "        clear_output(wait=True)\n",
    "        train_vis = {k: v[2:] for k, v in training_data.items()}\n",
    "        val_vis = {k: v[2:] for k, v in validation_data.items()}\n",
    "        \n",
    "        plot_training_curves(train_vis, val_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2702e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample from the trained model\n",
    "cvae.eval()\n",
    "with torch.no_grad():\n",
    "    # Get a batch from the test loader\n",
    "    x = next(iter(test_loader))\n",
    "    x = x.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = cvae(x)\n",
    "    px = outputs['px']\n",
    "    \n",
    "    # Get reconstruction (mean of the distribution)\n",
    "    x_hat = px.mean\n",
    "\n",
    "    # Move to cpu for plotting\n",
    "    # Select the first image in the batch\n",
    "    x_sample = x[0, 0].cpu().numpy()\n",
    "    x_hat_sample = x_hat[0, 0].cpu().numpy()\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Input\n",
    "    im1 = axes[0].imshow(x_sample.T, origin='lower', cmap='viridis')\n",
    "    axes[0].set_title(\"Input Sample\")\n",
    "    axes[0].axis('off')\n",
    "    fig.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Reconstruction\n",
    "    im2 = axes[1].imshow(x_hat_sample.T, origin='lower', cmap='viridis')\n",
    "    axes[1].set_title(\"Reconstructed Sample\")\n",
    "    axes[1].axis('off')\n",
    "    fig.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.suptitle(f\"VAE Reconstruction (Epoch {epoch})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_dtu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

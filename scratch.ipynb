{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "576f90fb",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b09ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 11 14:14:28 2024\n",
    "\n",
    "@author: alec\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from boutdata import collect\n",
    "import math \n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softplus\n",
    "from torch.distributions import Distribution\n",
    "\n",
    "\n",
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    \"\"\"\n",
    "    A distribution `N(y | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, 1)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: Tensor, log_sigma:Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        \"\"\"`\\eps ~ N(0, I)`\"\"\"\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (without gradients)\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
    "        epsilon = self.sample_epsilon()\n",
    "        return self.mu + self.sigma * epsilon\n",
    "            \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        \"\"\"return the log probability: log `p(z)`\"\"\"\n",
    "        return -0.5 * (math.log(2 * math.pi) + 2 * torch.log(self.sigma) + ((z - self.mu) ** 2) / (self.sigma ** 2))\n",
    "# Absolute path to either the BOUT output directory or an individual BOUT.dmp file.\n",
    "DATA_LOCATION = Path(\n",
    "\tr\"C:\\Users\\kenne\\OneDrive - Danmarks Tekniske Universitet\\Deep Learning DTU\\Data (1)\\Data\\Data_Files\\BOUT.dmp.0.nc\"\n",
    " )\n",
    "\n",
    "\n",
    "def load_density(path_hint: Path):\n",
    "\t\"\"\"Return the density field collected from BOUT output files.\"\"\"\n",
    "\tpath_hint = path_hint.expanduser().resolve()\n",
    "\n",
    "\t# If the user points at a single file we only need the parent directory.\n",
    "\tbout_dir = path_hint.parent if path_hint.is_file() else path_hint\n",
    "\n",
    "\tdensity = collect(\"pe\", path=str(bout_dir))\n",
    "\treturn density.squeeze()\n",
    "\n",
    "\n",
    "def plot_timestep(density,idx):\n",
    "\t\"\"\"Plot the density at the final time step.\"\"\"\n",
    "\tfig, ax = plt.subplots()\n",
    "\tcontour = ax.contourf(density[idx, :, :].T)\n",
    "\tfig.colorbar(contour, ax=ax, label=\"n (arb. units)\")\n",
    "\tax.set_title(\"Density at final timestep\")\n",
    "\tax.set_xlabel(\"x index\")\n",
    "\tax.set_ylabel(\"z index\")\n",
    "\tplt.show()\n",
    "\n",
    "#density_data = load_density(DATA_LOCATION)\n",
    "#plot_timestep(density_data,-1)\n",
    "density_data = torch.as_tensor(load_density(DATA_LOCATION), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8fe703",
   "metadata": {},
   "source": [
    "### Building the foundation of the convolutional-VAE\n",
    "\n",
    "The model of the convolutional-VAE will follow the following criteria:\n",
    "- A decoder and encoder that should be viewed as individual networks as to work independently\n",
    "- The encoder should be a convolutional network\n",
    "- The encoder should weigh the 'right' side of the images higher (use of kernel)\n",
    "- The latent space representation should be highly optimized to capture the important features of blobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_dtu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
